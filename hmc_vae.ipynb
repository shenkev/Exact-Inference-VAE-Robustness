{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from edward.models import Normal, Bernoulli, Empirical\n",
    "import edward as ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('./MNIST_data', one_hot=True)\n",
    "mb_size = 64\n",
    "z_dim = 100\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "h_dim = 128\n",
    "c = 0\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================== Q(z|X) Encoder ======================================\n",
    "\n",
    "Q_W1 = tf.Variable(xavier_init([X_dim, h_dim]))\n",
    "Q_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "Q_W2_mu = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_mu = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "Q_W2_sigma = tf.Variable(xavier_init([h_dim, z_dim]))\n",
    "Q_b2_sigma = tf.Variable(tf.zeros(shape=[z_dim]))\n",
    "\n",
    "\n",
    "def Q(X, reuse=True):\n",
    "    with tf.variable_scope('encoder', reuse=reuse):\n",
    "        h = tf.nn.relu(tf.matmul(X, Q_W1) + Q_b1)\n",
    "        z_mu = tf.matmul(h, Q_W2_mu) + Q_b2_mu\n",
    "        z_logvar = tf.matmul(h, Q_W2_sigma) + Q_b2_sigma\n",
    "        return z_mu, z_logvar\n",
    "\n",
    "# =============================== Sampling Helper ======================================\n",
    "def sample_z(mu, log_var):\n",
    "    eps = tf.random_normal(shape=tf.shape(mu))\n",
    "    return mu + tf.exp(log_var / 2) * eps\n",
    "\n",
    "# =============================== P(X|z) Decoder ======================================\n",
    "\n",
    "P_W1 = tf.Variable(xavier_init([z_dim, h_dim]))\n",
    "P_b1 = tf.Variable(tf.zeros(shape=[h_dim]))\n",
    "\n",
    "P_W2 = tf.Variable(xavier_init([h_dim, X_dim]))\n",
    "P_b2 = tf.Variable(tf.zeros(shape=[X_dim]))\n",
    "\n",
    "\n",
    "def P(z, reuse=True):\n",
    "    with tf.variable_scope('decoder', reuse=reuse):\n",
    "        h = tf.nn.relu(tf.matmul(z, P_W1) + P_b1)\n",
    "        logits = tf.matmul(h, P_W2) + P_b2\n",
    "        prob = tf.nn.sigmoid(logits)\n",
    "        return prob, logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# =============================== DEFINE LOSS ====================================\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_dim])\n",
    "z = tf.placeholder(tf.float32, shape=[None, z_dim])\n",
    "\n",
    "z_mu, z_logvar = Q(X)\n",
    "z_sample = sample_z(z_mu, z_logvar)\n",
    "_, logits = P(z_sample)\n",
    "\n",
    "# Sampling from random z\n",
    "X_samples, _ = P(z)\n",
    "\n",
    "# E[log P(X|z)]\n",
    "recon_loss = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=X), 1)\n",
    "# D_KL(Q(z|X) || P(z)); calculate in closed form as both dist. are Gaussian\n",
    "kl_loss = 0.5 * tf.reduce_sum(tf.exp(z_logvar) + z_mu**2 - 1. - z_logvar, 1)\n",
    "# VAE loss\n",
    "vae_loss = tf.reduce_mean(recon_loss + kl_loss)\n",
    "\n",
    "solver = tf.train.AdamOptimizer().minimize(vae_loss)\n",
    "\n",
    "# sess = tf.Session()\n",
    "sess = ed.get_session() # need to make sure tf and edward share the global session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== TRAINING ====================================\n",
    "i = 0\n",
    "max_iter = 20000\n",
    "\n",
    "for it in range(max_iter):\n",
    "    X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "\n",
    "    _, loss = sess.run([solver, vae_loss], feed_dict={X: X_mb})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('Loss: {:.4}'. format(loss))\n",
    "        print()\n",
    "\n",
    "        samples = sess.run(X_samples, feed_dict={z: np.random.randn(16, z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that VAE can Reconstruct GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "%matplotlib inline\n",
    "\n",
    "num_checks = 1\n",
    "x_gt, _ = mnist.train.next_batch(num_checks)\n",
    "plot(x_gt)\n",
    "plot(P(Q(x_gt)[0])[0].eval())\n",
    "_ = 1 # prevent repeated plot in jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_uninited_vars():\n",
    "    unint_vars = []\n",
    "    for var in tf.global_variables():\n",
    "        if not tf.is_variable_initialized(var).eval():\n",
    "            unint_vars.append(var)\n",
    "    missingVarInit = tf.variables_initializer (unint_vars)\n",
    "    sess.run(missingVarInit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMC Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEkAAABJCAYAAABxcwvcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAAdNJREFUeJzt27FqImEYheF3whYigr022k5jIWg1\nXpG3Y+uFDPZegb1oqyKD2P5bLNl1kGyOzcyX5DwQAhOLn5eTiRHNUkrY/721fYCvwJEEjiRwJIEj\nCRxJ4EgCRxI4kuDXKw/OsuzbPT1PKWWfPcZLEjiSwJEEjiRwJIEjCUJHyvOcPM+pqoqqqiiKgqIo\nGj/HS8+TmjadTgHo9XqtniP0kqIIuaT5fA7AarVq+SR/eEmCkEtar9dA+/eid16SwJEEjiQId0/q\ndrt0Op22j1HjJQnCLWmxWDAej9s+Ro2XJAi3pOFw+HTteDwCsNvtmj4O4CVJwi1puVw+XTufzwBc\nLpemjwN4SZIwS+r3+7Xvjw6HQ9PHqQkTaTKZADAajZ5+1vZLJv51EziSwJEE4e5Jj/b7PQDb7bbh\n09R5SYIwSzqdTk/X7vc7ALfbrenj1HhJgjBLGgwGbR/hQ16SIMySor3Q9shLEoRZ0vV6BSDLPn2f\nZ+O8JEGYSGVZUpYlKaW/X1GEiRSZIwkcSRDmr9v7f/ybzYbZbAb8ewtO27JXbpD+bIl9yJEEjiRw\nJIEjCRxJ4EiCl54n/VReksCRBI4kcCSBIwkcSeBIAkcSOJLAkQS/AcjGWFQmn9OyAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24126cab10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "inference_batch_size = 1\n",
    "x_gt, _ = mnist.train.next_batch(inference_batch_size)\n",
    "plot(x_gt)\n",
    "\n",
    "T = 5000 # number of empirical samples in posterior\n",
    "img_dim = 28\n",
    "hmc_steps = T\n",
    "leap_steps = 2\n",
    "\n",
    "z = Normal(loc=tf.zeros([inference_batch_size, z_dim]), scale=tf.ones([inference_batch_size, z_dim])) # sample z\n",
    "\n",
    "_, dec_x_logits = P(z)\n",
    "X = Bernoulli(logits=dec_x_logits)\n",
    "\n",
    "# X = Normal(loc=dec_x, scale=tf.ones(img_dim)*sig) # likelihood distrib\n",
    "qz = Empirical(params=tf.Variable(tf.zeros([T, inference_batch_size, z_dim])))\n",
    "\n",
    "inference = ed.HMC({z: qz}, data={X: x_gt})\n",
    "\n",
    "inference.initialize(step_size=0.05, n_steps=leap_steps)\n",
    "init_uninited_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tf.squeeze(qz.params, 1).eval());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [100%] ██████████████████████████████ Elapsed: 11s | Acceptance Rate: 0.981\n"
     ]
    }
   ],
   "source": [
    "for i in range(hmc_steps):\n",
    "    info_dict = inference.update()\n",
    "    inference.print_progress(info_dict)\n",
    "\n",
    "# inference.finalize()\n",
    "# inference.run(variables=[], n_steps=hmc_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-eb6a7d656784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_zeros\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mz_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.pyc\u001b[0m in \u001b[0;36mvariables_initializer\u001b[0;34m(var_list, name)\u001b[0m\n\u001b[1;32m   1268\u001b[0m   \"\"\"\n\u001b[1;32m   1269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'initializer'"
     ]
    }
   ],
   "source": [
    "all_zeros = tf.Variable(tf.zeros([1, z_dim]))\n",
    "sess.run(tf.variables_initializer([all_zeros]))\n",
    "zeros_img, _ = P(all_zeros)\n",
    "plot(zeros_img.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.update()\n",
    "keep_ratio = 0.2\n",
    "to_keep_index = int((1-keep_ratio)*T)\n",
    "qz_kept = Empirical(qz.params[to_keep_index:])\n",
    "\n",
    "z_test = tf.squeeze(qz_kept.sample(1), 0)\n",
    "print(z_test.eval())\n",
    "img, _ = P(z_test)\n",
    "plot(img.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from Posterior and Reconstruct Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_to_vis = 5\n",
    "qz_sample = qz_kept.sample(sample_to_vis)\n",
    "\n",
    "for i in range(sample_to_vis):\n",
    "    img, _ = P(qz_sample[i])\n",
    "    plot(img.eval())\n",
    "    \n",
    "avg_img, _ = P(tf.reduce_mean(qz_sample, 0))\n",
    "plot(avg_img.eval())"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/9ee7dcdeddd2116db9ffee9613bf0ab0"
  },
  "gist": {
   "data": {
    "description": "HMC_VAE.ipynb",
    "public": true
   },
   "id": "9ee7dcdeddd2116db9ffee9613bf0ab0"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
